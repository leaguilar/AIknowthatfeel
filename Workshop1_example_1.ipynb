{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/leaguilar/AIknowthatfeel/blob/master/Workshop1_example_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jjneDufNubN_"
   },
   "source": [
    "### Collab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1z45oeZoubOH"
   },
   "source": [
    "#### git clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fJGZWLXMubOJ"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/<your name>/<your project>.git\n",
    "#pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HqgyHHF-ubOP"
   },
   "source": [
    "#### Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vBLCOGqfubOQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N59G3tTgubOW",
    "outputId": "ed74839e-0210-453a-bca2-0760c1e4050f"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oKUB-WHMubOd"
   },
   "outputs": [],
   "source": [
    "from libs.workshop_libs.tensorboard import TrainValTensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "otrf-zNQubOi"
   },
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e8jxa9oWubOk"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify the default parameters of np.load  ### See below (problems with old numpy versions)\n",
    "# save np.load\n",
    "np_load_old = np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fl4uhLDlubOq"
   },
   "outputs": [],
   "source": [
    "top_words = 5000\n",
    "max_review_length = 500\n",
    "pad_char=0\n",
    "start_char=1\n",
    "oov_char=2\n",
    "index_from=3\n",
    "test_split=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yUBcwnm0ubOu"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_dev, y_dev) = imdb.load_data(seed=1,\n",
    "                                                      num_words=top_words,\n",
    "                                                      maxlen=max_review_length,\n",
    "                                                      start_char=start_char,\n",
    "                                                      oov_char=oov_char,\n",
    "                                                      index_from=index_from\n",
    "                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore np.load for future normal usage ### See below (problems with old numpy versions)\n",
    "np.load = np_load_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Jn2vCpTubOy",
    "outputId": "6c096b81-266e-4144-b733-83c50dbec1ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E-X1BY5WubO6",
    "outputId": "6cbb4cf0-4c54-439d-d151-9457b79793f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eg5OEz5yubO_",
    "outputId": "e4c4968d-15d6-4fd9-b955-1a882bacbf1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EhtEZV7gubPD",
    "outputId": "9311af59-dc67-48e8-f7d4-e06ebbe7965b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 13, 28, 1039, 7, 14, 23, 1856, 13, 104]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "feqlJyQIubPP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 13, 286, 1017, 3845, 3561, 21, 13, 16, 1383]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_dev[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X6WLnRTsubPZ"
   },
   "outputs": [],
   "source": [
    "max_data=10000\n",
    "x_train=x_train[0:max_data]\n",
    "y_train=y_train[0:max_data]\n",
    "x_dev=x_dev[0:max_data]\n",
    "y_dev=y_dev[0:max_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ooRRP6KgubPk"
   },
   "source": [
    "### Let's check the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zzwvqr1TubPn"
   },
   "outputs": [],
   "source": [
    "wordIDX = imdb.get_word_index()\n",
    "wordIDX = {k:(v+index_from) for k,v in wordIDX.items()}\n",
    "wordIDX[\"<>\"] = pad_char\n",
    "wordIDX[\"<INIT>\"] = start_char\n",
    "wordIDX[\"<?>\"] = oov_char\n",
    "IDXword = {value:key for key,value in wordIDX.items()}\n",
    "\n",
    "IDXsentiment={}\n",
    "IDXsentiment[0]=\"positive\"\n",
    "IDXsentiment[1]=\"negative\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SNQMCgPSubPt"
   },
   "outputs": [],
   "source": [
    "def printExample(x,y,i,IDXword,IDXsentiment):\n",
    "    print(\"=\"*10)\n",
    "    print(' '.join(IDXword[i] for i in x[i] ))\n",
    "    print('-'*10)\n",
    "    print('Sentiment: {}'.format(IDXsentiment[y[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SJzHGHmpubPy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "<INIT> i have copy of this on vhs i think they the television <?> should play this every year for the next twenty years so that we don't forget what was and that we remember not to do the same mistakes again like putting some people in the director's chair where they don't belong this movie <?> is like a <?> musical for those who can't sing or act this movie is as much fun as trying to teach the <?> to drive a city bus br br john hood <?> has just got out of prison and he's headed back to the old neighborhood in serving time for an all to nice crime of <?> of course john heads back onto the old street and is <?> by kids dogs old ladies and his <?> <?> as they dance and sing all along the way br br i would recommend this if i was sentimental or if in truth someone was smoking <?> pot <?> by a doctor for <?> either way this is a poorly directed scripted acted and even produced i never thought i'd sat that satire of <?> life with the <?> although i think the redeeming part of the story through the wannabe gang fight sequences and the dance numbers his friends care about their neighbors and want to save the <?> from being torn down and <?> up br br forget <?> <?> mario could have won an oscar for that in comparison to this rap oh well if you find yourself wanting to laugh yourself silly and three <?> embarrassed be sure to drink first br br and please watch <?> no stars better luck next time\n",
      "----------\n",
      "Sentiment: positive\n",
      "==========\n",
      "<INIT> after several extremely well ratings to the point of superb i was extremely pleased with the film the film was dark moving the anger the pain the guilt and a very extremely convincing demon br br i had initially expected to see many special effects and like a <?> <?> it blew me away with the subtlety and the <?> of it brian i am again blown away with your <?> with the telling of the story and your care of the special effects you will go a long way my friend i will definitely be the president of your fan club br br eric <?> the best actor award was the number one choice you made jr <?> look like a child compared to <?> br br overall the acting story line the high quality filming and awesome effects it was fantastic i just wish it were longer i am looking forward to the <?> with extremely high expectations\n",
      "----------\n",
      "Sentiment: negative\n",
      "==========\n",
      "<INIT> an <?> michael dies while returning from a mission and his body is <?> by the military the base where the dead <?> is taken to becomes the scene of a bizarre invasion plan from outer space alien <?> inside the dead <?> <?> the corpse and begin a terrifying assault on the military staff in the hopes of <?> the world according to the dvd <?> synopsis br br a roger <?> american international production the man who fell to earth <?> mr as john <?> does all right angela <?> is his pretty <?> <?> and ed nelson as dave <?> is featured as <?> with a bigger budget better opening and a re write for <?> <?> this could have been something <?> classic 1950s science fiction br br night of the blood beast <?> <?> l <?> roger <?> michael angela <?> ed nelson\n",
      "----------\n",
      "Sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "printExample(x_train,y_train,0,IDXword,IDXsentiment)\n",
    "printExample(x_train,y_train,1,IDXword,IDXsentiment)\n",
    "printExample(x_dev,y_dev,1,IDXword,IDXsentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "btMtYgP3ubP3"
   },
   "outputs": [],
   "source": [
    "x_dev_list=x_dev.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1HxfeB63ubP8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[100] in x_dev_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FsylYN8eubQA"
   },
   "outputs": [],
   "source": [
    "## Load tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XS_sP-BzubQD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard module is not an IPython extension.\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "#%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iEidhSvQubQG"
   },
   "outputs": [],
   "source": [
    "#!kill 4430"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D69WcXQ-ubQJ"
   },
   "outputs": [],
   "source": [
    "#!ps aux | grep -i tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h3QK8dxnubQL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "logs_base_dir = \"./logs\"\n",
    "os.makedirs(logs_base_dir, exist_ok=True)\n",
    "print(shutil.rmtree(logs_base_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C6P1sKbJubQN",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(logs_base_dir, exist_ok=True)\n",
    "%tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AdtCWEsjubQQ"
   },
   "outputs": [],
   "source": [
    "### Clean data, truncate y padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s2eLPnXcubQS"
   },
   "outputs": [],
   "source": [
    "def prepare_data(x_train,x_dev,max_review_length):\n",
    "    x_train = sequence.pad_sequences(x_train, maxlen=max_review_length)\n",
    "    x_dev = sequence.pad_sequences(x_dev, maxlen=max_review_length)\n",
    "    return x_train,x_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v_dvOac6ubQV"
   },
   "outputs": [],
   "source": [
    "def create_model(top_words,max_review_length):\n",
    "    embedding_vector_length = 32\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(top_words, embedding_vector_length, input_length=max_review_length))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J86tWELWubQY"
   },
   "outputs": [],
   "source": [
    "def train_model(model,x_train,y_train,x_dev,y_dev):\n",
    "        logdir = os.path.join(logs_base_dir, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy']\n",
    "                     )\n",
    "        model.fit(x_train,\n",
    "                  y_train,\n",
    "                  batch_size=128, #64,\n",
    "                  validation_data=(x_dev, y_dev),\n",
    "                  nb_epoch=10,\n",
    "                  callbacks=[TrainValTensorBoard(logdir, \n",
    "                                                 histogram_freq=1,\n",
    "                                                 write_graph=True\n",
    "                                                )]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WHxgWwrbubQb"
   },
   "outputs": [],
   "source": [
    "x_train,x_dev = prepare_data(x_train,x_dev,max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ex2pwHVXubQe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 500)\n",
      "(10000, 500)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uAtbYkHVubQg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model=create_model(top_words,max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BcxpHpEQubQj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 56s 6ms/step - loss: 0.6511 - acc: 0.6115 - val_loss: 0.5053 - val_acc: 0.7677\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 62s 6ms/step - loss: 0.3754 - acc: 0.8419 - val_loss: 0.4208 - val_acc: 0.8403\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 62s 6ms/step - loss: 0.2614 - acc: 0.8998 - val_loss: 0.4132 - val_acc: 0.8574\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 57s 6ms/step - loss: 0.2001 - acc: 0.9286 - val_loss: 0.4775 - val_acc: 0.8287\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 56s 6ms/step - loss: 0.1718 - acc: 0.9373 - val_loss: 0.7393 - val_acc: 0.7909\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 55s 6ms/step - loss: 0.2427 - acc: 0.9054 - val_loss: 0.3898 - val_acc: 0.8460\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 57s 6ms/step - loss: 0.1325 - acc: 0.9534 - val_loss: 0.4058 - val_acc: 0.8278\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 57s 6ms/step - loss: 0.1138 - acc: 0.9628 - val_loss: 0.4781 - val_acc: 0.8414\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 57s 6ms/step - loss: 0.0870 - acc: 0.9730 - val_loss: 0.5494 - val_acc: 0.8485\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 56s 6ms/step - loss: 0.0942 - acc: 0.9689 - val_loss: 0.4986 - val_acc: 0.8383\n"
     ]
    }
   ],
   "source": [
    "train_model(model,x_train,y_train,x_dev,y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7npijdPKubQm"
   },
   "source": [
    "### Let's evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SqInnV2HubQn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.83%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_dev, y_dev, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5VA35oLfubQr"
   },
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97OBEowKubQs"
   },
   "outputs": [],
   "source": [
    "outpath='models/'\n",
    "os.makedirs(outpath, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jjQsNhNmubQu"
   },
   "outputs": [],
   "source": [
    "model.save(outpath+\"model_other.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cIwHWrevubQx"
   },
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(outpath+\"model_other.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aIZRzaE_ubQz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "37YJvJcnubQ1"
   },
   "source": [
    "### One hot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p9cwWm4tubQ2"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w7QGC_rrubQ6"
   },
   "outputs": [],
   "source": [
    "texto=[\"This is a phrase\",\"This is a longer phrase\", \"another phrase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qId_CQ5JubQ9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29, 6, 17, 49], [29, 6, 17, 39, 49], [7, 49]]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 50\n",
    "vectorized_words = [one_hot(d, vocab_size) for d in texto]\n",
    "print(vectorized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QN5wEwrzubRA"
   },
   "source": [
    "### Problems with some numpy versions and keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zw2kMBJ8ubRB"
   },
   "outputs": [],
   "source": [
    "# save np.load\n",
    "np_load_old = np.load\n",
    "\n",
    "# modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "# call load_data with allow_pickle implicitly set to true\n",
    "#(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6LDgHH6vubRD"
   },
   "outputs": [],
   "source": [
    "# restore np.load for future normal usage\n",
    "np.load = np_load_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SKGlUiFXubRG"
   },
   "outputs": [],
   "source": [
    "### Another solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MRLs72jbubRK"
   },
   "outputs": [],
   "source": [
    "#!pip uninstall numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5EfqJ3YubRN"
   },
   "outputs": [],
   "source": [
    "#!pip install numpy==1.16.1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Workshop1_example_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
